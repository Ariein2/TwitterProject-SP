{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of COVID19 and BlackLivesMatter related tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code a sentiment analysis that compares  "
   ]
  },
  {
   "source": [
    "## 1. Import all packages <p>\n",
    "***WARNING***: Before trying to load the packages make sure they are installed in the python environment you are working with. The specific packages used (not common packages) can be installed following the instructions from: <br>\n",
    "- [GetOldTweets3] (https://pypi.org/project/GetOldTweets3/)\n",
    "- [VaderSentimentAnalysis] (https://github.com/cjhutto/vaderSentiment)\n",
    "- [sklearn] (https://github.com/scikit-learn/scikit-learn)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Load packages\n",
    "import GetOldTweets3 as got\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "from sklearn.svm import OneClassSVM"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retreive tweets with certain hashtag <p>\n",
    "To extract historical tweets from Twitter the package GetOldTweets was used. This package uses the twitter API to crawl for tweets containing a certain searchword. The query search has to be performed directly from the terminal by running the following code lines. It will search for all the tweets that can be found based on the search criteria specified and it will save the tweet and some related information in a csv file. The specifications in the search critera will be: <p>\n",
    "\n",
    "- **querysearch:** The word used for the query search. In this case several hashtags will be used. <br>\n",
    "- **since and until:** Allow to set the timeframe in which the tweets will be retreived. <br>\n",
    "- **top tweets:** Only stores tweets regarded by Twitter as Top tweets, usually they have more favourites, replies and retweets.<br>\n",
    "- **lang:** Filters the language of the tweets retreived. en: English <br>\n",
    "- **output:** Determines the name of the output file in which hte tweets are stored. <p>\n",
    "\n",
    "**10-15th May 2020** <br>\n",
    "* GetOldTweets3 --querysearch \"#kitten\" --since \"2020-05-10\" --until \"2020-05-15\" --toptweets --maxtweets 10000 --lang en --output \"kitten10M.csv\"<br>\n",
    "* GetOldTweets3 --querysearch \"#pet\" --since \"2020-05-10\" --until \"2020-05-15\" --toptweets --maxtweets 10000 --lang en --output \"pet10M.csv\"<br>\n",
    "* GetOldTweets3 --querysearch \"#COVID19\" --since \"2020-05-10\" --until \"2020-05-15\" --toptweets --maxtweets 10000 --lang en --output \"COVID10M.csv\"<br>\n",
    "* GetOldTweets3 --querysearch \"#BlackLivesMatter\" --since \"2020-05-10\" --until \"2020-05-15\" --toptweets --maxtweets 10000 --lang en --output \"BLM10M.csv\"<p>\n",
    "\n",
    "**26- 31 May 2020** <br>\n",
    "* GetOldTweets3 --querysearch \"#BlackLivesMatter\" --since \"2020-05-26\" --until \"2020-05-31\" --toptweets --maxtweets 10000 --lang en --output \"BLM26M.csv\"<br>\n",
    "* GetOldTweets3 --querysearch \"#kitten\" --since \"2020-05-26\" --until \"2020-05-31\" --toptweets --maxtweets 10000 --lang en --output \"kitten26M.csv\"<br>\n",
    "* GetOldTweets3 --querysearch \"#pet\" --since \"2020-05-26\" --until \"2020-05-31\" --toptweets --maxtweets 10000 --lang en --output \"pet26M.csv\"  <br>\n",
    "* GetOldTweets3 --querysearch \"#COVID19\" --since \"2020-05-26\" --until \"2020-05-31\" --toptweets --maxtweets 10000 --lang en --output \"COVID26M.csv\" <p>\n",
    "\n",
    "To increase reproducibility, the exact files used for the example analysis are also provided with this code. Therefore it is not necessary to run the GetOldTweets3 query.  <br>"
   ]
  },
  {
   "source": [
    "## 3. Load data from .csv files <p>\n",
    "\n",
    "The data extracted in the previous step has to be reloaded for its analysis. If the user did not use the GetOldTweets3 package to extract the data it is also possible to load other .csv files containing tweets for their further analsis. Nevertheless, make sure they contain the same structure than the [tweet class](https://pypi.org/project/GetOldTweets3/) created by GetOldTweets3. <p> \n",
    "**INSTRUCTIONS:** To load the data introduce the name of each .csv file in one element of the namefiles list and run this block of code. <p> \n",
    "\n",
    "Each csv files will be stored as a new key in a common dictionary (data_all). The key name is the name of the specific file and the value associated to the key contains a list of lists that stores all the variables retreived for each tweet sample. \n",
    "\n",
    "**NOTE:** Make sure that the files are located in the same folder than the .ipnyb main file and the names are written exactly in the same way than the file to load (with no extra spaces at the start or the end of the string). ***WARNING: Case sensitive!***\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace elements in the list by the name of the .csv files to load\n",
    "namefiles = ['BLM10M', 'BLM26M', \n",
    "            'COVID10M', 'COVID26M', \n",
    "            'kitten10M', 'kitten26M', \n",
    "            'pet10M', 'pet26M']\n",
    "\n",
    "# Load all csv files\n",
    "all_data = {}\n",
    "\n",
    "for dataset in namefiles:\n",
    "    with open(dataset + '.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        list_reader = list(reader)\n",
    "        all_data[dataset] = list_reader"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ScientificProg': conda)",
   "language": "python",
   "name": "python38564bitscientificprogcondacb715e50313a4501b48237fbd7669a4c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}