{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of COVID19 and BlackLivesMatter related tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code a sentiment analysis that compares  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import GetOldTweets3 as got\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retreive tweets with certain hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract historical tweets from Twitter the package GetOldTweets was used. This package uses the twitter API to crawl for tweets containing a certain searchword. The query search has to be performed directly from the terminal by running the following code lines. It will search for all the tweets that can be found based on the search criteria specified and it will save the tweet and some related information in a csv file. The specifications in the search critera will be: <p>\n",
    "    **querysearch:** The word used for the query search. In this case several hashtags will be used. <br>\n",
    "    **since and until:** Allow to set the timeframe in which the tweets will be retreived. <br>\n",
    "    **top tweets:** Only stores tweets regarded by Twitter as Top tweets, usually they have more favourites, replies and retweets.<br>\n",
    "    **lang:** Filters the language of the tweets retreived. en: English <br>\n",
    "    **output:** Determines the name of the output file in which hte tweets are stored. <p>\n",
    "**10-15th May 2020** <br>\n",
    "GetOldTweets3 --querysearch \"#kitten\" --since \"2020-05-10\" --until \"2020-05-15\" --toptweets --maxtweets 10000 --lang en --output \"kitten10M.csv\"<br>\n",
    "GetOldTweets3 --querysearch \"#pet\" --since \"2020-05-10\" --until \"2020-05-15\" --toptweets --maxtweets 10000 --lang en --output \"pet10M.csv\"<br>\n",
    "GetOldTweets3 --querysearch \"#COVID19\" --since \"2020-05-10\" --until \"2020-05-15\" --toptweets --maxtweets 10000 --lang en --output \"COVID10M.csv\"<br>\n",
    "GetOldTweets3 --querysearch \"#BlackLivesMatter\" --since \"2020-05-10\" --until \"2020-05-15\" --toptweets --maxtweets 10000 --lang en --output \"BLM10M.csv\"<p>\n",
    "\n",
    "**26- 31 May 2020** <br>\n",
    "GetOldTweets3 --querysearch \"#BlackLivesMatter\" --since \"2020-05-26\" --until \"2020-05-31\" --toptweets --maxtweets 10000 --lang en --output \"BLM26M.csv\"<br>\n",
    "GetOldTweets3 --querysearch \"#kitten\" --since \"2020-05-26\" --until \"2020-05-31\" --toptweets --maxtweets 10000 --lang en --output \"kitten26M.csv\"<br>\n",
    "GetOldTweets3 --querysearch \"#pet\" --since \"2020-05-26\" --until \"2020-05-31\" --toptweets --maxtweets 10000 --lang en --output \"pet26M.csv\"  <br>\n",
    "GetOldTweets3 --querysearch \"#COVID19\" --since \"2020-05-26\" --until \"2020-05-31\" --toptweets --maxtweets 10000 --lang en --output \"COVID26M.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load data from .csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the elements in namefiles with the name of the CSV files to load.\n",
    "# (All files must be located in the same folder as the python script) \n",
    "\n",
    "namefiles = ['BLM10M', 'BLM26M', \n",
    "            'COVID10M', 'COVID26M', \n",
    "            'kitten10M', 'kitten26M', \n",
    "            'pet10M', 'pet26M']\n",
    "\n",
    "# Load all csv files\n",
    "all_data = {}\n",
    "\n",
    "for dataset in namefiles:\n",
    "    with open(dataset + '.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        list_reader = list(reader)\n",
    "        all_data[dataset] = list_reader\n",
    "\n",
    "# Each csv file is stored as a list in the all_data dictionary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ScientificProg': conda)",
   "language": "python",
   "name": "python38564bitscientificprogcondacb715e50313a4501b48237fbd7669a4c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}